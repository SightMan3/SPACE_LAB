{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d7f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from scipy.ndimage import shift\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00a4671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce GTX 1650 Ti is available.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"dw|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac8f2c",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316d7eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time1</th>\n",
       "      <th>Rot$</th>\n",
       "      <th>IMF</th>\n",
       "      <th>PLS</th>\n",
       "      <th>IMF_PTS</th>\n",
       "      <th>PLS_PTS</th>\n",
       "      <th>ABS_B</th>\n",
       "      <th>F</th>\n",
       "      <th>THETA_AV</th>\n",
       "      <th>...</th>\n",
       "      <th>F10_INDEX+48</th>\n",
       "      <th>BZ_GSE+1</th>\n",
       "      <th>BZ_GSE+2</th>\n",
       "      <th>BZ_GSE+3</th>\n",
       "      <th>BZ_GSE+4</th>\n",
       "      <th>BZ_GSE+6</th>\n",
       "      <th>BZ_GSE+8</th>\n",
       "      <th>BZ_GSE+12</th>\n",
       "      <th>BZ_GSE+24</th>\n",
       "      <th>BZ_GSE+48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1963-01-01 01:00:00</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1963-01-01 02:00:00</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1963-01-01 03:00:00</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1963-01-01 04:00:00</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1963-01-01 05:00:00</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520438</th>\n",
       "      <td>520438</td>\n",
       "      <td>2022-05-13 12:00:00</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>135.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520439</th>\n",
       "      <td>520439</td>\n",
       "      <td>2022-05-13 13:00:00</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>135.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520440</th>\n",
       "      <td>520440</td>\n",
       "      <td>2022-05-13 14:00:00</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>135.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520441</th>\n",
       "      <td>520441</td>\n",
       "      <td>2022-05-13 15:00:00</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>135.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520442</th>\n",
       "      <td>520442</td>\n",
       "      <td>2022-05-13 16:00:00</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>135.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520443 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                time1    Rot$   IMF   PLS  IMF_PTS  PLS_PTS  \\\n",
       "0                0  1963-01-01 01:00:00  1771.0  99.0  99.0    999.0    999.0   \n",
       "1                1  1963-01-01 02:00:00  1771.0  99.0  99.0    999.0    999.0   \n",
       "2                2  1963-01-01 03:00:00  1771.0  99.0  99.0    999.0    999.0   \n",
       "3                3  1963-01-01 04:00:00  1771.0  99.0  99.0    999.0    999.0   \n",
       "4                4  1963-01-01 05:00:00  1771.0  99.0  99.0    999.0    999.0   \n",
       "...            ...                  ...     ...   ...   ...      ...      ...   \n",
       "520438      520438  2022-05-13 12:00:00  9999.0  99.0  99.0    999.0    999.0   \n",
       "520439      520439  2022-05-13 13:00:00  9999.0  99.0  99.0    999.0    999.0   \n",
       "520440      520440  2022-05-13 14:00:00  9999.0  99.0  99.0    999.0    999.0   \n",
       "520441      520441  2022-05-13 15:00:00  9999.0  99.0  99.0    999.0    999.0   \n",
       "520442      520442  2022-05-13 16:00:00  9999.0  99.0  99.0    999.0    999.0   \n",
       "\n",
       "        ABS_B   F  THETA_AV  ...  F10_INDEX+48  BZ_GSE+1  BZ_GSE+2  BZ_GSE+3  \\\n",
       "0         NaN NaN       NaN  ...           NaN       NaN       NaN       NaN   \n",
       "1         NaN NaN       NaN  ...           NaN       NaN       NaN       NaN   \n",
       "2         NaN NaN       NaN  ...           NaN       NaN       NaN       NaN   \n",
       "3         NaN NaN       NaN  ...           NaN       NaN       NaN       NaN   \n",
       "4         NaN NaN       NaN  ...           NaN       NaN       NaN       NaN   \n",
       "...       ...  ..       ...  ...           ...       ...       ...       ...   \n",
       "520438    NaN NaN       NaN  ...    135.600006       NaN       NaN       NaN   \n",
       "520439    NaN NaN       NaN  ...    135.600006       NaN       NaN       NaN   \n",
       "520440    NaN NaN       NaN  ...    135.600006       NaN       NaN       NaN   \n",
       "520441    NaN NaN       NaN  ...    135.600006       NaN       NaN       NaN   \n",
       "520442    NaN NaN       NaN  ...    135.600006       NaN       NaN       NaN   \n",
       "\n",
       "        BZ_GSE+4  BZ_GSE+6  BZ_GSE+8  BZ_GSE+12  BZ_GSE+24  BZ_GSE+48  \n",
       "0            NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "1            NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "2            NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "3            NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "4            NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "...          ...       ...       ...        ...        ...        ...  \n",
       "520438       NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "520439       NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "520440       NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "520441       NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "520442       NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "\n",
       "[520443 rows x 83 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/omni_full_1964-2022.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3025af07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rot$', 'IMF', 'PLS', 'IMF_PTS', 'PLS_PTS', 'ABS_B', 'F', 'THETA_AV',\n",
       "       'PHI_AV', 'BX_GSE', 'BY_GSE', 'BZ_GSE', 'BY_GSM', 'BZ_GSM',\n",
       "       'SIGMA$ABS_B', 'SIGMA$B', 'SIGMA$Bx', 'SIGMA$By', 'SIGMA$Bz', 'T', 'N',\n",
       "       'V', 'PHI$V', 'THETA$V', 'Ratio', 'Pressure', 'SIGMA$T', 'SIGMA$N',\n",
       "       'SIGMA$V', 'SIGMA$PHI$V', 'SIGMA$THETA$V', 'SIGMA$ratio', 'E', 'Beta',\n",
       "       'Mach_num', 'Mgs_mach_num', 'PR$FLX_1', 'PR$FLX_2', 'PR$FLX_4',\n",
       "       'PR$FLX_10', 'PR$FLX_30', 'PR$FLX_60', 'MFLX', 'R', 'F10_INDEX', 'KP',\n",
       "       'DST', 'AE', 'AP_INDEX', 'AL_INDEX', 'AU_INDEX', 'PC_N_INDEX',\n",
       "       'Solar_Lyman_alpha', 'Proton_QI', 'DST+1', 'DST+2', 'DST+3', 'DST+4',\n",
       "       'DST+6', 'DST+8', 'DST+12', 'DST+24', 'DST+48', 'F10_INDEX+1',\n",
       "       'F10_INDEX+2', 'F10_INDEX+3', 'F10_INDEX+4', 'F10_INDEX+6',\n",
       "       'F10_INDEX+8', 'F10_INDEX+12', 'F10_INDEX+24', 'F10_INDEX+48',\n",
       "       'BZ_GSE+1', 'BZ_GSE+2', 'BZ_GSE+3', 'BZ_GSE+4', 'BZ_GSE+6', 'BZ_GSE+8',\n",
       "       'BZ_GSE+12', 'BZ_GSE+24', 'BZ_GSE+48'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.index = data['time1']\n",
    "data.drop('time1', axis=1, inplace=True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2466cb77-8ae3-4adc-9dc7-3e91ee3de0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dst_shift_minus1 = data['DST'].shift(-1, fill_value=0).loc[\"1995-01-01 00:00:00\":]\n",
    "data_dst_shift_minus1.name = 'DST-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b5404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BZ_GSE       977\n",
       "V            903\n",
       "N           5586\n",
       "DST            0\n",
       "SIGMA$Bz     977\n",
       "DST-1          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_relevant = data[['BZ_GSE', 'V', 'N', 'DST', 'SIGMA$Bz']].loc[\"1995-01-01 00:00:00\":]\n",
    "data_relevant = pd.concat([data_relevant, data_dst_shift_minus1], axis=1)\n",
    "data_relevant.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2ec062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BZ_GSE      0\n",
       "V           0\n",
       "N           0\n",
       "DST         0\n",
       "SIGMA$Bz    0\n",
       "DST-1       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_relevant.index = pd.to_datetime(data_relevant.index)\n",
    "data_relevant_interpolated = data_relevant.interpolate(method='time')\n",
    "data_relevant_interpolated.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a17a8e",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b91bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BZ_GSE</th>\n",
       "      <th>V</th>\n",
       "      <th>N</th>\n",
       "      <th>DST</th>\n",
       "      <th>SIGMA$Bz</th>\n",
       "      <th>DST-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <td>0.131579</td>\n",
       "      <td>-0.818939</td>\n",
       "      <td>-0.763676</td>\n",
       "      <td>0.683367</td>\n",
       "      <td>-0.976134</td>\n",
       "      <td>0.683367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <td>0.131579</td>\n",
       "      <td>-0.818939</td>\n",
       "      <td>-0.763676</td>\n",
       "      <td>0.683367</td>\n",
       "      <td>-0.976134</td>\n",
       "      <td>0.703407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-01 01:00:00</th>\n",
       "      <td>0.149123</td>\n",
       "      <td>-0.818939</td>\n",
       "      <td>-0.727206</td>\n",
       "      <td>0.703407</td>\n",
       "      <td>-0.961814</td>\n",
       "      <td>0.715431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-01 02:00:00</th>\n",
       "      <td>0.168860</td>\n",
       "      <td>-0.808533</td>\n",
       "      <td>-0.719912</td>\n",
       "      <td>0.715431</td>\n",
       "      <td>-0.914081</td>\n",
       "      <td>0.711423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-01 03:00:00</th>\n",
       "      <td>0.184211</td>\n",
       "      <td>-0.814776</td>\n",
       "      <td>-0.762217</td>\n",
       "      <td>0.711423</td>\n",
       "      <td>-0.961814</td>\n",
       "      <td>0.703407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13 12:00:00</th>\n",
       "      <td>0.184211</td>\n",
       "      <td>-0.829344</td>\n",
       "      <td>-0.905179</td>\n",
       "      <td>0.699399</td>\n",
       "      <td>-0.904535</td>\n",
       "      <td>0.707415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13 13:00:00</th>\n",
       "      <td>0.184211</td>\n",
       "      <td>-0.829344</td>\n",
       "      <td>-0.905179</td>\n",
       "      <td>0.707415</td>\n",
       "      <td>-0.904535</td>\n",
       "      <td>0.711423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13 14:00:00</th>\n",
       "      <td>0.184211</td>\n",
       "      <td>-0.829344</td>\n",
       "      <td>-0.905179</td>\n",
       "      <td>0.711423</td>\n",
       "      <td>-0.904535</td>\n",
       "      <td>0.711423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13 15:00:00</th>\n",
       "      <td>0.184211</td>\n",
       "      <td>-0.829344</td>\n",
       "      <td>-0.905179</td>\n",
       "      <td>0.711423</td>\n",
       "      <td>-0.904535</td>\n",
       "      <td>0.707415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13 16:00:00</th>\n",
       "      <td>0.184211</td>\n",
       "      <td>-0.829344</td>\n",
       "      <td>-0.905179</td>\n",
       "      <td>0.707415</td>\n",
       "      <td>-0.904535</td>\n",
       "      <td>0.691383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239901 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       BZ_GSE         V         N       DST  SIGMA$Bz  \\\n",
       "time1                                                                   \n",
       "1995-01-01 00:00:00  0.131579 -0.818939 -0.763676  0.683367 -0.976134   \n",
       "1995-01-01 00:00:00  0.131579 -0.818939 -0.763676  0.683367 -0.976134   \n",
       "1995-01-01 01:00:00  0.149123 -0.818939 -0.727206  0.703407 -0.961814   \n",
       "1995-01-01 02:00:00  0.168860 -0.808533 -0.719912  0.715431 -0.914081   \n",
       "1995-01-01 03:00:00  0.184211 -0.814776 -0.762217  0.711423 -0.961814   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2022-05-13 12:00:00  0.184211 -0.829344 -0.905179  0.699399 -0.904535   \n",
       "2022-05-13 13:00:00  0.184211 -0.829344 -0.905179  0.707415 -0.904535   \n",
       "2022-05-13 14:00:00  0.184211 -0.829344 -0.905179  0.711423 -0.904535   \n",
       "2022-05-13 15:00:00  0.184211 -0.829344 -0.905179  0.711423 -0.904535   \n",
       "2022-05-13 16:00:00  0.184211 -0.829344 -0.905179  0.707415 -0.904535   \n",
       "\n",
       "                        DST-1  \n",
       "time1                          \n",
       "1995-01-01 00:00:00  0.683367  \n",
       "1995-01-01 00:00:00  0.703407  \n",
       "1995-01-01 01:00:00  0.715431  \n",
       "1995-01-01 02:00:00  0.711423  \n",
       "1995-01-01 03:00:00  0.703407  \n",
       "...                       ...  \n",
       "2022-05-13 12:00:00  0.707415  \n",
       "2022-05-13 13:00:00  0.711423  \n",
       "2022-05-13 14:00:00  0.711423  \n",
       "2022-05-13 15:00:00  0.707415  \n",
       "2022-05-13 16:00:00  0.691383  \n",
       "\n",
       "[239901 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = data_relevant_interpolated.min()\n",
    "max_val = data_relevant_interpolated.max()\n",
    "\n",
    "# Normalize between -1 and 1\n",
    "data_relevant_interpolated_normalized = 2 * (data_relevant_interpolated - min_val) / (max_val - min_val) - 1\n",
    "data_relevant_interpolated_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa602e",
   "metadata": {},
   "source": [
    "# Generate [batch, sequence, features] shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093ef920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, target_col, sequence_length):\n",
    "    \"\"\"\n",
    "    Creates input-output sequences for GRU training, with the target shifted forward by one time step.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame containing features and target.\n",
    "        target_col (str): Name of the column for the target variable (e.g., \"DST\").\n",
    "        sequence_length (int): Length of each input sequence.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (X, y) where:\n",
    "            - X is a NumPy array of shape (num_samples, sequence_length, num_features).\n",
    "            - y is a NumPy array of shape (num_samples, 1).\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - sequence_length - 1):  # Ensure there is a target one step ahead\n",
    "        # Extract a sequence of features\n",
    "        seq = data.iloc[i:i + sequence_length].drop(columns=[target_col]).values\n",
    "        # Extract the target value corresponding to one step ahead of the last time step in the sequence\n",
    "        target = data.iloc[i + sequence_length][target_col]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets).reshape(-1, 1)\n",
    "\n",
    "# Example usage\n",
    "sequence_length = 10  # Adjust based on your problem\n",
    "X, y = create_sequences(data_relevant_interpolated_normalized, target_col=\"DST\", sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16ced4f-67b5-416f-bffb-51b16ebb8ba1",
   "metadata": {},
   "source": [
    "## Prepare for training\n",
    "- Splitting to train, test and valdation sets\n",
    "- converting to tensor\n",
    "- Making dataset loaders for batching purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7908b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: Further split training set into train/validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a42cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75925914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=138, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=138, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=138, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eecfea05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([153529, 10, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896879a",
   "metadata": {},
   "source": [
    "# Define RNN model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4099501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # GRU forward pass\n",
    "        with torch.backends.cudnn.flags(enabled=False):\n",
    "            out, _ = self.gru(x, h0)\n",
    "        # Fully connected layer\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time step's output\n",
    "        return out\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # GRU forward pass\n",
    "        with torch.backends.cudnn.flags(enabled=False):\n",
    "            out, _ = self.rnn(x, h0)\n",
    "        # Fully connected layer\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time step's output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77d971d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DstEventWeightedMSELoss(torch.nn.Module):\n",
    "    '''\n",
    "    psi - event treshold\n",
    "    ksi - event weight\n",
    "    phi - base weight\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, psi, ksi, phi):\n",
    "        super(DstEventWeightedMSELoss, self).__init__()\n",
    "\n",
    "        self.psi = psi\n",
    "        self.ksi = ksi\n",
    "        self.phi = phi\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        \n",
    "    def forward(self, y_pred, y_real):\n",
    "        losses = self.mse_loss(y_pred, y_real)\n",
    "\n",
    "        event_weights = torch.where(\n",
    "            y_real <= self.psi,\n",
    "            self.ksi,\n",
    "            self.phi\n",
    "        )\n",
    "\n",
    "        return (losses * event_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "163c26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, loader, optimizer, criterion):\n",
    "    # Training loop\n",
    "    history = []\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_inputs, batch_targets in loader:\n",
    "            batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        history.append(avg_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.10f}\")\n",
    "\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss += criterion(val_outputs, val_targets).item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.10f}\")\n",
    "        \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caf39a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0170879976\n",
      "Validation Loss: 0.0038519738\n",
      "Epoch [2/50], Loss: 0.0020529237\n",
      "Validation Loss: 0.0015106901\n",
      "Epoch [3/50], Loss: 0.0011430908\n",
      "Validation Loss: 0.0009440711\n",
      "Epoch [4/50], Loss: 0.0007826890\n",
      "Validation Loss: 0.0006904607\n",
      "Epoch [5/50], Loss: 0.0005725434\n",
      "Validation Loss: 0.0005181980\n",
      "Epoch [6/50], Loss: 0.0004278424\n",
      "Validation Loss: 0.0003899852\n",
      "Epoch [7/50], Loss: 0.0003179645\n",
      "Validation Loss: 0.0002911850\n",
      "Epoch [8/50], Loss: 0.0002376008\n",
      "Validation Loss: 0.0002221148\n",
      "Epoch [9/50], Loss: 0.0001779412\n",
      "Validation Loss: 0.0001644866\n",
      "Epoch [10/50], Loss: 0.0001314491\n",
      "Validation Loss: 0.0001253016\n",
      "Epoch [11/50], Loss: 0.0000968310\n",
      "Validation Loss: 0.0000913291\n",
      "Epoch [12/50], Loss: 0.0000693245\n",
      "Validation Loss: 0.0000645873\n",
      "Epoch [13/50], Loss: 0.0000480600\n",
      "Validation Loss: 0.0000445171\n",
      "Epoch [14/50], Loss: 0.0000314497\n",
      "Validation Loss: 0.0000282363\n",
      "Epoch [15/50], Loss: 0.0000191631\n",
      "Validation Loss: 0.0000154214\n",
      "Epoch [16/50], Loss: 0.0000102679\n",
      "Validation Loss: 0.0000071121\n",
      "Epoch [17/50], Loss: 0.0000046385\n",
      "Validation Loss: 0.0000027766\n",
      "Epoch [18/50], Loss: 0.0000018906\n",
      "Validation Loss: 0.0000011553\n",
      "Epoch [19/50], Loss: 0.0000010866\n",
      "Validation Loss: 0.0000011653\n",
      "Epoch [20/50], Loss: 0.0000009812\n",
      "Validation Loss: 0.0000006140\n",
      "Epoch [21/50], Loss: 0.0000008332\n",
      "Validation Loss: 0.0000005430\n",
      "Epoch [22/50], Loss: 0.0000008237\n",
      "Validation Loss: 0.0000007794\n",
      "Epoch [23/50], Loss: 0.0000007410\n",
      "Validation Loss: 0.0000004983\n",
      "Epoch [24/50], Loss: 0.0000007252\n",
      "Validation Loss: 0.0000008107\n",
      "Epoch [25/50], Loss: 0.0000006572\n",
      "Validation Loss: 0.0000004451\n",
      "Epoch [26/50], Loss: 0.0000006159\n",
      "Validation Loss: 0.0000003490\n",
      "Epoch [27/50], Loss: 0.0000005858\n",
      "Validation Loss: 0.0000004908\n",
      "Epoch [28/50], Loss: 0.0000005929\n",
      "Validation Loss: 0.0000003683\n",
      "Epoch [29/50], Loss: 0.0000005109\n",
      "Validation Loss: 0.0000009419\n",
      "Epoch [30/50], Loss: 0.0000005828\n",
      "Validation Loss: 0.0000008618\n",
      "Epoch [31/50], Loss: 0.0000005310\n",
      "Validation Loss: 0.0000011249\n",
      "Epoch [32/50], Loss: 0.0000004891\n",
      "Validation Loss: 0.0000003090\n",
      "Epoch [33/50], Loss: 0.0000005122\n",
      "Validation Loss: 0.0000003725\n",
      "Epoch [34/50], Loss: 0.0000004404\n",
      "Validation Loss: 0.0000005432\n",
      "Epoch [35/50], Loss: 0.0000004651\n",
      "Validation Loss: 0.0000002690\n",
      "Epoch [36/50], Loss: 0.0000004403\n",
      "Validation Loss: 0.0000005388\n",
      "Epoch [37/50], Loss: 0.0000004352\n",
      "Validation Loss: 0.0000003566\n",
      "Epoch [38/50], Loss: 0.0000004161\n",
      "Validation Loss: 0.0000003395\n",
      "Epoch [39/50], Loss: 0.0000004302\n",
      "Validation Loss: 0.0000003107\n",
      "Epoch [40/50], Loss: 0.0000003879\n",
      "Validation Loss: 0.0000003283\n",
      "Epoch [41/50], Loss: 0.0000004180\n",
      "Validation Loss: 0.0000003907\n",
      "Epoch [42/50], Loss: 0.0000004020\n",
      "Validation Loss: 0.0000002727\n",
      "Epoch [43/50], Loss: 0.0000003788\n",
      "Validation Loss: 0.0000007302\n",
      "Epoch [44/50], Loss: 0.0000003877\n",
      "Validation Loss: 0.0000002699\n",
      "Epoch [45/50], Loss: 0.0000003516\n",
      "Validation Loss: 0.0000006045\n",
      "Epoch [46/50], Loss: 0.0000003548\n",
      "Validation Loss: 0.0000002278\n",
      "Epoch [47/50], Loss: 0.0000003836\n",
      "Validation Loss: 0.0000006295\n",
      "Epoch [48/50], Loss: 0.0000003497\n",
      "Validation Loss: 0.0000002433\n",
      "Epoch [49/50], Loss: 0.0000003344\n",
      "Validation Loss: 0.0000003123\n",
      "Epoch [50/50], Loss: 0.0000003348\n",
      "Validation Loss: 0.0000004002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e9470980d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model parameters\n",
    "input_size = 5  # Bz, sigma Bz, n, v, t, f\n",
    "hidden_size = 26\n",
    "output_size = 1  # DST index\n",
    "num_layers = 1\n",
    "epochs = 50\n",
    "alpha = 0.0001\n",
    "\n",
    "# Initialize the GRU model\n",
    "gru = GRUModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size, num_layers=num_layers)\n",
    "rnn = RNNModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size, num_layers=num_layers)\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = DstEventWeightedMSELoss(psi=0.5, ksi=4, phi=1)\n",
    "optim = torch.optim.Adam(rnn.parameters(), lr=alpha)\n",
    "\n",
    "h = train(epochs, rnn, train_loader, optim, loss_fn)\n",
    "plt.plot(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef43ecb-d5d2-4320-b36c-3731811f8c70",
   "metadata": {},
   "source": [
    "# Shapely values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739efb3c-fdac-4251-ba2f-4cc47bef861c",
   "metadata": {},
   "source": [
    "## Testing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e57231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f818b33c-0d7d-42f3-bde2-49d73218f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gru.eval()\n",
    "# y_real  = []\n",
    "# y_preds = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for x_test, y_test in test_loader:\n",
    "#         test_inputs, test_targets = x_test.to('cuda'), y_test.to('cuda')\n",
    "        \n",
    "#         # Forward pass to get predictions\n",
    "#         outputs = gru(test_inputs)\n",
    "        \n",
    "#         # Store predictions and true values\n",
    "#         y_preds.extend(outputs.cpu().numpy())  # Convert to NumPy for easier handling\n",
    "#         y_real.extend(test_targets.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc529783-f94f-4c2a-9c95-5195c8bdd0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "# plt.plot(y_real)\n",
    "# plt.plot(y_preds, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e97b1-e611-4e9e-b865-51cfda5be291",
   "metadata": {},
   "source": [
    "## Prepare event data for shapely value calculation\n",
    "Choosing an event period from dataset, to see clearly which parameters affect predicting storms the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4643a4b-f253-4d53-b8ae-8786286f19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "event1 = data_relevant_interpolated_normalized.loc['2015-03-01':'2015-04-01']\n",
    "event_x, event_y = create_sequences(event1, target_col=\"DST\", sequence_length=sequence_length)\n",
    "\n",
    "event_x = torch.tensor(event_x, dtype=torch.float32)\n",
    "event_y = torch.tensor(event_y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54f1724c-621d-45ad-83ae-a48f49151bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_events_x, some_events_y = create_sequences(data_relevant_interpolated_normalized.loc[\"2000-01-01\":\"2010-12-31\"], target_col=\"DST\", sequence_length=sequence_length)\n",
    "all_data_for_shapely_x = torch.tensor(\n",
    "    some_events_x, \n",
    "    dtype=torch.float32\n",
    ")\n",
    "all_data_for_shapely_y = torch.tensor(\n",
    "    some_events_y, \n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf46e6c-7db6-4e4e-93e2-e02d015eab1b",
   "metadata": {},
   "source": [
    "## Calculate shapely values for event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2666a924-60e3-4c79-a040-c00bdbf88200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 5, 1), (1, 10, 5))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_data = next(iter(train_loader))[0][:10].to('cuda')  # Use the first 10 samples as background\n",
    "\n",
    "# Step 2: Create a SHAP explainer\n",
    "explainer = shap.DeepExplainer(rnn, background_data)\n",
    "\n",
    "# Step 3: Compute SHAP values for a sample input\n",
    "sample_input = next(iter(train_loader))[0][:1].to('cuda')  # Use the first sample for explanation\n",
    "shap_values = explainer.shap_values(sample_input)\n",
    "\n",
    "# Step 4: Reshape shap_values and sample_input for visualization\n",
    "# shap_values is a list of arrays (one per output feature), so we take the first element\n",
    "shap_values = shap_values[0]  # Shape: (batch_size, seq_length, num_features)\n",
    "sample_input = sample_input.cpu().numpy()  # Shape: (batch_size, seq_length, num_featu|res)\n",
    "\n",
    "shap_values.shape, sample_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfad830-7ef8-4513-9c63-5be872331f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the results\n",
    "shap.initjs()\n",
    "\n",
    "# Force plot for a single prediction\n",
    "# Flatten the sequence dimension to visualize all time steps together\n",
    "# shap.force_plot(\n",
    "#     explainer.expected_value,\n",
    "#     shap_values.reshape(-1, shap_values.shape[-1]),  # Flatten seq_length dimension\n",
    "#     sample_input.reshape(-1, sample_input.shape[-1]),  # Flatten seq_length dimension\n",
    "#     feature_names=['Bz', 'sigma Bz', 'N', 'V', 'DST']\n",
    "# )\n",
    "\n",
    "# Summary plot for overall feature importance\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    sample_input,\n",
    "    feature_names=['Bz', 'sigma Bz', 'N', 'V', 'DST']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce324a60-7836-450f-b517-f62abdeec997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1316, -0.7211, -0.9664, -0.9666,  0.6673],\n",
       "         [ 0.1667, -0.7357, -0.9416, -0.9236,  0.6754],\n",
       "         [ 0.1338, -0.7336, -0.9241, -0.9666,  0.6673],\n",
       "         [ 0.1557, -0.7482, -0.9198, -0.9618,  0.6713],\n",
       "         [ 0.1689, -0.7440, -0.9212, -0.9714,  0.6754],\n",
       "         [ 0.1601, -0.7482, -0.9416, -0.9379,  0.6633],\n",
       "         [ 0.1908, -0.7627, -0.9416, -0.9809,  0.6633],\n",
       "         [ 0.1798, -0.7565, -0.9460, -0.9618,  0.6754],\n",
       "         [ 0.1601, -0.7711, -0.8979, -0.9618,  0.6713],\n",
       "         [ 0.1798, -0.7960, -0.8993, -0.9857,  0.6754]],\n",
       "\n",
       "        [[ 0.2412, -0.8273, -0.7097, -0.8663,  0.7355],\n",
       "         [ 0.0351, -0.8293, -0.8600, -0.8711,  0.7114],\n",
       "         [ 0.0175, -0.8210, -0.8643, -0.9714,  0.7074],\n",
       "         [ 0.0570, -0.8127, -0.8731, -0.8950,  0.6954],\n",
       "         [ 0.0855, -0.8065, -0.8906, -0.9427,  0.6954],\n",
       "         [ 0.0789, -0.7794, -0.8906, -0.9332,  0.6834],\n",
       "         [ 0.1009, -0.7815, -0.8993, -0.9523,  0.6954],\n",
       "         [ 0.1491, -0.7898, -0.8862, -0.9714,  0.7074],\n",
       "         [ 0.1776, -0.7919, -0.8920, -0.9666,  0.7154],\n",
       "         [ 0.1645, -0.7960, -0.8935, -0.9618,  0.7315]],\n",
       "\n",
       "        [[ 0.2303, -0.4880, -0.9810, -0.9857,  0.6152],\n",
       "         [ 0.1820, -0.4901, -0.9825, -0.9761,  0.6152],\n",
       "         [ 0.1820, -0.4506, -0.9825, -0.9761,  0.6192],\n",
       "         [ 0.1886, -0.4797, -0.9825, -0.9761,  0.6112],\n",
       "         [ 0.1732, -0.5276, -0.9810, -0.9714,  0.6152],\n",
       "         [ 0.1798, -0.5442, -0.9737, -0.9714,  0.6152],\n",
       "         [ 0.1732, -0.5338, -0.9679, -0.9714,  0.6152],\n",
       "         [ 0.1864, -0.5734, -0.9664, -0.9475,  0.6152],\n",
       "         [ 0.1864, -0.6025, -0.9650, -0.9666,  0.6192],\n",
       "         [ 0.1798, -0.5879, -0.9577, -0.9475,  0.6232]],\n",
       "\n",
       "        [[ 0.1952, -0.6837, -0.9460, -0.9714,  0.6794],\n",
       "         [ 0.1798, -0.7024, -0.9460, -0.9427,  0.6914],\n",
       "         [ 0.1952, -0.7045, -0.9475, -0.9714,  0.6914],\n",
       "         [ 0.1689, -0.7315, -0.9475, -0.9475,  0.6914],\n",
       "         [ 0.1952, -0.7357, -0.9489, -0.9857,  0.6954],\n",
       "         [ 0.1930, -0.7565, -0.9504, -0.9761,  0.6914],\n",
       "         [ 0.1732, -0.7648, -0.9489, -0.9714,  0.6914],\n",
       "         [ 0.1469, -0.7669, -0.9504, -0.9761,  0.6874],\n",
       "         [ 0.1689, -0.7627, -0.9548, -0.9666,  0.6914],\n",
       "         [ 0.1754, -0.7565, -0.9548, -0.9761,  0.6834]],\n",
       "\n",
       "        [[ 0.1535, -0.7773, -0.8629, -0.9761,  0.7074],\n",
       "         [ 0.1360, -0.7773, -0.8614, -0.9714,  0.6954],\n",
       "         [ 0.1447, -0.7856, -0.8658, -0.9857,  0.7074],\n",
       "         [ 0.1623, -0.7981, -0.8833, -0.9857,  0.7114],\n",
       "         [ 0.1689, -0.7940, -0.8775, -0.9809,  0.6954],\n",
       "         [ 0.1776, -0.7898, -0.8804, -0.9761,  0.6914],\n",
       "         [ 0.1842, -0.7898, -0.8775, -0.9761,  0.6994],\n",
       "         [ 0.1667, -0.7960, -0.8833, -0.9809,  0.7114],\n",
       "         [ 0.1908, -0.8023, -0.8804, -0.9523,  0.7154],\n",
       "         [ 0.1952, -0.7981, -0.8629, -0.9761,  0.7154]],\n",
       "\n",
       "        [[ 0.2215, -0.7877, -0.8629, -0.8807,  0.7836],\n",
       "         [ 0.1842, -0.7960, -0.8585, -0.8902,  0.7916],\n",
       "         [ 0.2368, -0.8106, -0.8614, -0.9189,  0.7956],\n",
       "         [ 0.2018, -0.8106, -0.8673, -0.9236,  0.7916],\n",
       "         [ 0.2500, -0.8169, -0.8614, -0.9666,  0.7876],\n",
       "         [ 0.2171, -0.8085, -0.8060, -0.9379,  0.7836],\n",
       "         [ 0.2237, -0.7877, -0.8162, -0.9379,  0.7756],\n",
       "         [ 0.2215, -0.7794, -0.8352, -0.9714,  0.7635],\n",
       "         [ 0.1974, -0.7856, -0.8439, -0.9857,  0.7475],\n",
       "         [ 0.2303, -0.7877, -0.8570, -0.9427,  0.7435]],\n",
       "\n",
       "        [[ 0.2719, -0.7690, -0.9037, -0.9475,  0.5992],\n",
       "         [ 0.1645, -0.8127, -0.8848, -0.8807,  0.5912],\n",
       "         [ 0.1360, -0.8231, -0.8862, -0.9523,  0.5952],\n",
       "         [ 0.1908, -0.8293, -0.8862, -0.9809,  0.6112],\n",
       "         [ 0.2193, -0.8231, -0.9008, -0.8998,  0.6192],\n",
       "         [ 0.2895, -0.7940, -0.9125, -0.9666,  0.6152],\n",
       "         [ 0.2654, -0.8169, -0.9168, -0.9857,  0.6192],\n",
       "         [ 0.1250, -0.8106, -0.9125, -0.7947,  0.6032],\n",
       "         [ 0.1228, -0.8252, -0.9125, -0.8425,  0.5952],\n",
       "         [ 0.0417, -0.8065, -0.9023, -0.8950,  0.5752]],\n",
       "\n",
       "        [[ 0.2083, -0.4547, -0.9037, -0.9332,  0.6553],\n",
       "         [ 0.2149, -0.4547, -0.9227, -0.9570,  0.6633],\n",
       "         [ 0.1996, -0.4610, -0.9241, -0.9523,  0.6593],\n",
       "         [ 0.1798, -0.4901, -0.9431, -0.9570,  0.6673],\n",
       "         [ 0.2434, -0.4922, -0.9402, -0.9332,  0.6713],\n",
       "         [ 0.2368, -0.5005, -0.9446, -0.9475,  0.6633],\n",
       "         [ 0.2018, -0.4922, -0.9548, -0.9618,  0.6673],\n",
       "         [ 0.2149, -0.4860, -0.9606, -0.9761,  0.6713],\n",
       "         [ 0.1776, -0.4755, -0.9708, -0.9523,  0.6713],\n",
       "         [ 0.2105, -0.4860, -0.9606, -0.9618,  0.6713]],\n",
       "\n",
       "        [[ 0.2259, -0.2674, -0.9519, -0.9427,  0.5872],\n",
       "         [ 0.1689, -0.2799, -0.9562, -0.9141,  0.5872],\n",
       "         [ 0.1754, -0.3049, -0.9621, -0.9618,  0.5792],\n",
       "         [ 0.1689, -0.2924, -0.9679, -0.9284,  0.5952],\n",
       "         [ 0.2149, -0.2986, -0.9679, -0.9523,  0.6072],\n",
       "         [ 0.1974, -0.3153, -0.9679, -0.9618,  0.5952],\n",
       "         [ 0.1689, -0.3195, -0.9694, -0.9379,  0.5792],\n",
       "         [ 0.1996, -0.3299, -0.9708, -0.9666,  0.5832],\n",
       "         [ 0.1930, -0.3444, -0.9737, -0.9666,  0.5671],\n",
       "         [ 0.1996, -0.3424, -0.9694, -0.9523,  0.5591]],\n",
       "\n",
       "        [[ 0.1096, -0.2903, -0.9548, -0.9379,  0.6273],\n",
       "         [ 0.1118, -0.2778, -0.9533, -0.9570,  0.6313],\n",
       "         [ 0.1798, -0.2924, -0.9504, -0.8998,  0.6353],\n",
       "         [ 0.2303, -0.2591, -0.9533, -0.8950,  0.6313],\n",
       "         [ 0.1864, -0.2196, -0.9635, -0.9427,  0.6313],\n",
       "         [ 0.1601, -0.2300, -0.9606, -0.9666,  0.6473],\n",
       "         [ 0.2061, -0.1675, -0.9533, -0.8950,  0.6673],\n",
       "         [ 0.2368, -0.1322, -0.9475, -0.8568,  0.6633],\n",
       "         [ 0.1645, -0.0905, -0.9344, -0.8282,  0.6553],\n",
       "         [ 0.1798, -0.0489, -0.9387, -0.8663,  0.6393]]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8e33f-e4f6-489e-bb6e-30dde3ce06d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
